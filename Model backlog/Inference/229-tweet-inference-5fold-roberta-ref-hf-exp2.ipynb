{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import json, glob\n",
    "from tweet_utility_scripts import *\n",
    "from tweet_utility_preprocess_roberta_scripts_aux import *\n",
    "from transformers import TFRobertaModel, RobertaConfig\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 3534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAX_LEN': 64,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'EPOCHS': 7,\n",
       " 'LEARNING_RATE': 3e-05,\n",
       " 'ES_PATIENCE': 2,\n",
       " 'N_FOLDS': 5,\n",
       " 'question_size': 4,\n",
       " 'base_model_path': '/kaggle/input/qa-transformers/roberta/roberta-base-tf_model.h5',\n",
       " 'config_path': '/kaggle/input/qa-transformers/roberta/roberta-base-config.json'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_base_path = '/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/'\n",
    "with open(input_base_path + 'config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_1.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_2.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_3.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_4.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_5.h5\n"
     ]
    }
   ],
   "source": [
    "vocab_path = input_base_path + 'vocab.json'\n",
    "merges_path = input_base_path + 'merges.txt'\n",
    "base_path = '/kaggle/input/qa-transformers/roberta/'\n",
    "\n",
    "# vocab_path = base_path + 'roberta-base-vocab.json'\n",
    "# merges_path = base_path + 'roberta-base-merges.txt'\n",
    "config['base_model_path'] = base_path + 'roberta-base-tf_model.h5'\n",
    "config['config_path'] = base_path + 'roberta-base-config.json'\n",
    "\n",
    "model_path_list = glob.glob(input_base_path + 'model' + '*.h5')\n",
    "model_path_list.sort()\n",
    "\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(vocab_file=vocab_path, merges_file=merges_path, \n",
    "                                  lowercase=True, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'].fillna('', inplace=True)\n",
    "test['text'] = test['text'].apply(lambda x: x.lower())\n",
    "test['text'] = test['text'].apply(lambda x: x.strip())\n",
    "\n",
    "x_test, x_test_aux, x_test_aux_2 = get_data_test(test, tokenizer, config['MAX_LEN'], preprocess_fn=preprocess_roberta_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_config = RobertaConfig.from_pretrained(config['config_path'], output_hidden_states=False)\n",
    "\n",
    "def model_fn(MAX_LEN):\n",
    "    input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    base_model = TFRobertaModel.from_pretrained(config['base_model_path'], config=module_config, name=\"base_model\")\n",
    "    last_hidden_state, _  = base_model({'input_ids': input_ids, 'attention_mask': attention_mask})\n",
    "    \n",
    "    logits = layers.Dense(2, name=\"qa_outputs\")(last_hidden_state)\n",
    "    \n",
    "    start_logits, end_logits = tf.split(logits, 2, axis=-1)\n",
    "    start_logits = tf.squeeze(start_logits, axis=-1)\n",
    "    end_logits = tf.squeeze(end_logits, axis=-1)\n",
    "\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[start_logits, end_logits])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_1.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_2.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_3.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_4.h5\n",
      "/kaggle/input/229-tweet-train-5fold-roberta-reference-hf-exp2/model_fold_5.h5\n"
     ]
    }
   ],
   "source": [
    "NUM_TEST_IMAGES = len(test)\n",
    "test_start_preds = np.zeros((NUM_TEST_IMAGES, config['MAX_LEN']))\n",
    "test_end_preds = np.zeros((NUM_TEST_IMAGES, config['MAX_LEN']))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    print(model_path)\n",
    "    model = model_fn(config['MAX_LEN'])\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    test_preds = model.predict(get_test_dataset(x_test, config['BATCH_SIZE']))  \n",
    "    test_start_preds += test_preds[0]\n",
    "    test_end_preds += test_preds[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "test['start'] = test_start_preds.argmax(axis=-1)\n",
    "test['end'] = test_end_preds.argmax(axis=-1)\n",
    "\n",
    "test['selected_text'] = test.apply(lambda x: decode(x['start'], x['end'], x['text'], config['question_size'], tokenizer), axis=1)\n",
    "\n",
    "# Post-process\n",
    "\n",
    "test[\"selected_text\"] = test.apply(lambda x: ' '.join([word for word in x['selected_text'].split() if word in x['text'].split()]), axis=1)\n",
    "test['selected_text'] = test.apply(lambda x: x['text'] if (x['selected_text'] == '') else x['selected_text'], axis=1)\n",
    "test['selected_text'].fillna(test['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>label_len</th>\n",
       "      <th>text_wordCnt</th>\n",
       "      <th>label_wordCnt</th>\n",
       "      <th>text_tokenCnt</th>\n",
       "      <th>label_tokenCnt</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>last session of the day</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting (precisely --...</td>\n",
       "      <td>positive</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>exciting</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>recession hit veronique branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>such a shame!</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - i like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>i like it!!</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726e501993</td>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>that`s great!!</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>261932614e</td>\n",
       "      <td>i think everyone hates me on here   lol</td>\n",
       "      <td>negative</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>hates</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>afa11da83f</td>\n",
       "      <td>soooooo wish i could, but im in school and mys...</td>\n",
       "      <td>negative</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>blocked</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e64208b4ef</td>\n",
       "      <td>and within a short time of the last clue all o...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>and within a short time of the last clue all o...</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37bcad24ca</td>\n",
       "      <td>what did you get?  my day is alright.. haven`t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>what did you get? my day is alright.. haven`t ...</td>\n",
       "      <td>103</td>\n",
       "      <td>102</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729  shanghai is also really exciting (precisely --...  positive   \n",
       "2  eee518ae67  recession hit veronique branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - i like it!!  positive   \n",
       "5  726e501993                    that`s great!! weee!! visitors!  positive   \n",
       "6  261932614e            i think everyone hates me on here   lol  negative   \n",
       "7  afa11da83f  soooooo wish i could, but im in school and mys...  negative   \n",
       "8  e64208b4ef  and within a short time of the last clue all o...   neutral   \n",
       "9  37bcad24ca  what did you get?  my day is alright.. haven`t...   neutral   \n",
       "\n",
       "   start  end                                      selected_text  text_len  \\\n",
       "0      4    8                            last session of the day        49   \n",
       "1     10   10                                           exciting       102   \n",
       "2     20   23                                      such a shame!        78   \n",
       "3      4    7                                        happy bday!        11   \n",
       "4     17   20                                        i like it!!        38   \n",
       "5      4    8                                     that`s great!!        31   \n",
       "6      7    7                                              hates        39   \n",
       "7     20   20                                            blocked        72   \n",
       "8      4   15  and within a short time of the last clue all o...        52   \n",
       "9      4   29  what did you get? my day is alright.. haven`t ...       103   \n",
       "\n",
       "   label_len  text_wordCnt  label_wordCnt  text_tokenCnt  label_tokenCnt  \\\n",
       "0         23             7              5             17               5   \n",
       "1          8            17              1             33               1   \n",
       "2         13            13              3             20               4   \n",
       "3         11             2              2              4               4   \n",
       "4         11             5              3             17               4   \n",
       "5         14             4              2             10               5   \n",
       "6          5            10              1             10               1   \n",
       "7          7            13              1             17               1   \n",
       "8         52            12             12             12              12   \n",
       "9        102            19             18             26              25   \n",
       "\n",
       "    jaccard  \n",
       "0  0.833333  \n",
       "1  0.066667  \n",
       "2  0.230769  \n",
       "3  1.000000  \n",
       "4  0.600000  \n",
       "5  0.500000  \n",
       "6  0.125000  \n",
       "7  0.076923  \n",
       "8  1.000000  \n",
       "9  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text_len</th>\n",
       "      <th>label_len</th>\n",
       "      <th>text_wordCnt</th>\n",
       "      <th>label_wordCnt</th>\n",
       "      <th>text_tokenCnt</th>\n",
       "      <th>label_tokenCnt</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.334748</td>\n",
       "      <td>16.798529</td>\n",
       "      <td>67.326259</td>\n",
       "      <td>35.600736</td>\n",
       "      <td>13.185059</td>\n",
       "      <td>6.863328</td>\n",
       "      <td>18.197510</td>\n",
       "      <td>9.437748</td>\n",
       "      <td>0.578260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.077369</td>\n",
       "      <td>9.896443</td>\n",
       "      <td>35.609555</td>\n",
       "      <td>36.611955</td>\n",
       "      <td>7.113988</td>\n",
       "      <td>7.112038</td>\n",
       "      <td>9.808701</td>\n",
       "      <td>9.883525</td>\n",
       "      <td>0.413383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.585784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             start          end     text_len    label_len  text_wordCnt  \\\n",
       "count  3534.000000  3534.000000  3534.000000  3534.000000   3534.000000   \n",
       "mean      8.334748    16.798529    67.326259    35.600736     13.185059   \n",
       "std       7.077369     9.896443    35.609555    36.611955      7.113988   \n",
       "min       4.000000     4.000000     3.000000     2.000000      1.000000   \n",
       "25%       4.000000     9.000000    38.000000     7.000000      7.000000   \n",
       "50%       4.000000    15.000000    62.000000    19.000000     12.000000   \n",
       "75%      11.000000    23.000000    96.000000    53.000000     19.000000   \n",
       "max      44.000000    57.000000   142.000000   137.000000     35.000000   \n",
       "\n",
       "       label_wordCnt  text_tokenCnt  label_tokenCnt      jaccard  \n",
       "count    3534.000000    3534.000000     3534.000000  3534.000000  \n",
       "mean        6.863328      18.197510        9.437748     0.578260  \n",
       "std         7.112038       9.808701        9.883525     0.413383  \n",
       "min         1.000000       1.000000        1.000000     0.033333  \n",
       "25%         1.000000      10.000000        2.000000     0.142857  \n",
       "50%         4.000000      17.000000        5.000000     0.585784  \n",
       "75%        10.000000      26.000000       14.000000     1.000000  \n",
       "max        32.000000      68.000000       68.000000     1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['text_len'] = test['text'].apply(lambda x : len(x))\n",
    "test['label_len'] = test['selected_text'].apply(lambda x : len(x))\n",
    "test['text_wordCnt'] = test['text'].apply(lambda x : len(x.split(' ')))\n",
    "test['label_wordCnt'] = test['selected_text'].apply(lambda x : len(x.split(' ')))\n",
    "test['text_tokenCnt'] = test['text'].apply(lambda x : len(tokenizer.encode(x).ids))\n",
    "test['label_tokenCnt'] = test['selected_text'].apply(lambda x : len(tokenizer.encode(x).ids))\n",
    "test['jaccard'] = test.apply(lambda x: jaccard(x['text'], x['selected_text']), axis=1)\n",
    "\n",
    "display(test.head(10))\n",
    "display(test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>such a shame!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>i like it!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726e501993</td>\n",
       "      <td>that`s great!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>261932614e</td>\n",
       "      <td>hates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>afa11da83f</td>\n",
       "      <td>blocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e64208b4ef</td>\n",
       "      <td>and within a short time of the last clue all o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37bcad24ca</td>\n",
       "      <td>what did you get? my day is alright.. haven`t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                      selected_text\n",
       "0  f87dea47db                            last session of the day\n",
       "1  96d74cb729                                           exciting\n",
       "2  eee518ae67                                      such a shame!\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5                                        i like it!!\n",
       "5  726e501993                                     that`s great!!\n",
       "6  261932614e                                              hates\n",
       "7  afa11da83f                                            blocked\n",
       "8  e64208b4ef  and within a short time of the last clue all o...\n",
       "9  37bcad24ca  what did you get? my day is alright.. haven`t ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\n",
    "submission['selected_text'] = test['selected_text']\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
