{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from tweet_utility_scripts import *\n",
    "from transformers import TFDistilBertModel\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 3535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11aa4945ff</td>\n",
       "      <td>http://twitpic.com/67swx - i wish i was calli...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd1db57dc0</td>\n",
       "      <td>i'm done.haha. HOUSE MD marathon ulet</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2524332d66</td>\n",
       "      <td>I'm concerned for that family</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0fb19285b2</td>\n",
       "      <td>HEY GUYS IT'S WORKING NO NEED TO WORRY. i have...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6c9e5e3ab</td>\n",
       "      <td>26th February</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  11aa4945ff   http://twitpic.com/67swx - i wish i was calli...  positive\n",
       "1  fd1db57dc0              i'm done.haha. HOUSE MD marathon ulet  positive\n",
       "2  2524332d66                      I'm concerned for that family  positive\n",
       "3  0fb19285b2  HEY GUYS IT'S WORKING NO NEED TO WORRY. i have...  positive\n",
       "4  e6c9e5e3ab                                      26th February   neutral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/8-tweet-train-distilbert-lower-avg-max/model.h5\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "base_path = '/kaggle/input/qa-transformers/distilbert/'\n",
    "base_model_path = base_path + 'distilbert-base-uncased-distilled-squad-tf_model.h5'\n",
    "config_path = base_path + 'distilbert-base-uncased-distilled-squad-config.json'\n",
    "\n",
    "input_base_path = '/kaggle/input/8-tweet-train-distilbert-lower-avg-max/'\n",
    "tokenizer_path = base_path + 'bert-large-uncased-vocab.txt'\n",
    "model_path_list = glob.glob(input_base_path + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(tokenizer_path , lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'].fillna('', inplace=True)\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: x.lower())\n",
    "\n",
    "x_test = get_data_test(test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')\n",
    "    token_type_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name='token_type_ids')\n",
    "    \n",
    "    base_model = TFDistilBertModel.from_pretrained(base_model_path, config=config_path, name=\"base_model\")\n",
    "    sequence_output = base_model({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids})\n",
    "    last_state = sequence_output[0]\n",
    "    \n",
    "    avg_p = GlobalAveragePooling1D()(last_state)\n",
    "    max_p = GlobalMaxPooling1D()(last_state)\n",
    "    \n",
    "    x = Concatenate()([avg_p, max_p])\n",
    "    \n",
    "    y_start = Dense(MAX_LEN, activation='softmax', name='y_start')(x)\n",
    "    y_end = Dense(MAX_LEN, activation='softmax', name='y_end')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask, token_type_ids], outputs=[y_start, y_end])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/8-tweet-train-distilbert-lower-avg-max/model.h5\n"
     ]
    }
   ],
   "source": [
    "NUM_TEST_IMAGES = len(test)\n",
    "test_start_preds = np.zeros((NUM_TEST_IMAGES, MAX_LEN))\n",
    "test_end_preds = np.zeros((NUM_TEST_IMAGES, MAX_LEN))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    print(model_path)\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    test_preds = model.predict(x_test)                    \n",
    "    test_start_preds += test_preds[0] / len(model_path_list)\n",
    "    test_end_preds += test_preds[1] / len(model_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "test['start'] = test_start_preds.argmax(axis=-1)\n",
    "test['end'] = test_end_preds.argmax(axis=-1)\n",
    "test['selected_text'] = test.apply(lambda x: decode(x['start'], x['end'], x['text'], tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11aa4945ff</td>\n",
       "      <td>http://twitpic.com/67swx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd1db57dc0</td>\n",
       "      <td>i'm done.haha. house md marathon ulet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2524332d66</td>\n",
       "      <td>i'm concerned for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0fb19285b2</td>\n",
       "      <td>hey guys it's working no need to worry. i have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6c9e5e3ab</td>\n",
       "      <td>26th february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>311d2b185b</td>\n",
       "      <td>breaks my achy breaky heart they split ways in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95dfefd4e7</td>\n",
       "      <td>well off 2 bed...cant wait 2 party 4 mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>739f17cfe1</td>\n",
       "      <td>oh yeah the camera clipping problems with void...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c6322a85c2</td>\n",
       "      <td>_layne hmm.. what's ur fav movie??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b4401d6b4d</td>\n",
       "      <td>salt and vinegar, cheese and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                      selected_text\n",
       "0  11aa4945ff                          http://twitpic.com/67swx \n",
       "1  fd1db57dc0              i'm done.haha. house md marathon ulet\n",
       "2  2524332d66                                 i'm concerned for \n",
       "3  0fb19285b2  hey guys it's working no need to worry. i have...\n",
       "4  e6c9e5e3ab                                      26th february\n",
       "5  311d2b185b    breaks my achy breaky heart they split ways in \n",
       "6  95dfefd4e7        well off 2 bed...cant wait 2 party 4 mother\n",
       "7  739f17cfe1  oh yeah the camera clipping problems with void...\n",
       "8  c6322a85c2                _layne hmm.. what's ur fav movie?? \n",
       "9  b4401d6b4d                      salt and vinegar, cheese and "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\n",
    "submission['selected_text'] = test[\"selected_text\"]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
