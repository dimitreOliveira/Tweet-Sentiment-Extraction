{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import TFDistilBertModel\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "# Transformer inputs\n",
    "def preprocess_test(text, context, tokenizer, max_seq_len):\n",
    "    context_encoded = tokenizer.encode(context)\n",
    "    context_encoded = context_encoded.ids[1:-1]\n",
    "    \n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded.pad(max_seq_len)\n",
    "    encoded.truncate(max_seq_len)\n",
    "    input_ids = encoded.ids\n",
    "    attention_mask = encoded.attention_mask\n",
    "    token_type_ids = ([0] * 3) + ([1] * (max_seq_len - 3))\n",
    "    \n",
    "    input_ids = [101] + context_encoded + [102] + input_ids\n",
    "    # update input ids and attentions masks size\n",
    "    input_ids = input_ids[:-3]\n",
    "    attention_mask = [1] * 3 + attention_mask[:-3]\n",
    "    \n",
    "    x = [np.asarray(input_ids, dtype=np.int32), \n",
    "         np.asarray(attention_mask, dtype=np.int32), \n",
    "         np.asarray(token_type_ids, dtype=np.int32)]\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_data_test(df, tokenizer, MAX_LEN):\n",
    "    x_input_ids = []\n",
    "    x_attention_masks = []\n",
    "    x_token_type_ids = []\n",
    "    for row in df.itertuples(): \n",
    "        x = preprocess_test(getattr(row, \"text\"), getattr(row, \"sentiment\"), tokenizer, MAX_LEN)\n",
    "        x_input_ids.append(x[0])\n",
    "        x_attention_masks.append(x[1])\n",
    "        x_token_type_ids.append(x[2])\n",
    "\n",
    "    x_data = [np.asarray(x_input_ids), np.asarray(x_attention_masks), np.asarray(x_token_type_ids)]\n",
    "    return x_data\n",
    "\n",
    "def decode(pred_start, pred_end, text, tokenizer):\n",
    "    offset = tokenizer.encode(text).offsets\n",
    "    \n",
    "    if pred_end >= len(offset):\n",
    "        pred_end = len(offset)-1\n",
    "        \n",
    "    decoded_text = \"\"\n",
    "    for i in range(pred_start, pred_end+1):\n",
    "        decoded_text += text[offset[i][0]:offset[i][1]]\n",
    "        if (i+1) < len(offset) and offset[i][1] < offset[i+1][0]:\n",
    "            decoded_text += \" \"\n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 3535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11aa4945ff</td>\n",
       "      <td>http://twitpic.com/67swx - i wish i was calli...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd1db57dc0</td>\n",
       "      <td>i'm done.haha. HOUSE MD marathon ulet</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2524332d66</td>\n",
       "      <td>I'm concerned for that family</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0fb19285b2</td>\n",
       "      <td>HEY GUYS IT'S WORKING NO NEED TO WORRY. i have...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6c9e5e3ab</td>\n",
       "      <td>26th February</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  11aa4945ff   http://twitpic.com/67swx - i wish i was calli...  positive\n",
       "1  fd1db57dc0              i'm done.haha. HOUSE MD marathon ulet  positive\n",
       "2  2524332d66                      I'm concerned for that family  positive\n",
       "3  0fb19285b2  HEY GUYS IT'S WORKING NO NEED TO WORRY. i have...  positive\n",
       "4  e6c9e5e3ab                                      26th February   neutral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/6-tweet-train-distilbert-lower-bce-v2/model.h5\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "base_path = '/kaggle/input/qa-transformers/distilbert/'\n",
    "base_model_path = base_path + 'distilbert-base-uncased-distilled-squad-tf_model.h5'\n",
    "config_path = base_path + 'distilbert-base-uncased-distilled-squad-config.json'\n",
    "\n",
    "input_base_path = '/kaggle/input/6-tweet-train-distilbert-lower-bce-v2/'\n",
    "tokenizer_path = input_base_path + 'vocab.txt'\n",
    "model_path_list = glob.glob(input_base_path + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(tokenizer_path , lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'].fillna('', inplace=True)\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: x.lower())\n",
    "\n",
    "x_test = get_data_test(test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')\n",
    "    token_type_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name='token_type_ids')\n",
    "    \n",
    "    base_model = TFDistilBertModel.from_pretrained(base_model_path, config=config_path, name=\"base_model\")\n",
    "    sequence_output = base_model({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids})\n",
    "    last_state = sequence_output[0]\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(last_state)\n",
    "    \n",
    "    y_start = Dense(MAX_LEN, activation='sigmoid', name='y_start')(x)\n",
    "    y_end = Dense(MAX_LEN, activation='sigmoid', name='y_end')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask, token_type_ids], outputs=[y_start, y_end])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/6-tweet-train-distilbert-lower-bce-v2/model.h5\n"
     ]
    }
   ],
   "source": [
    "NUM_TEST_IMAGES = len(test)\n",
    "test_start_preds = np.zeros((NUM_TEST_IMAGES, MAX_LEN))\n",
    "test_end_preds = np.zeros((NUM_TEST_IMAGES, MAX_LEN))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    print(model_path)\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    test_preds = model.predict(x_test)                    \n",
    "    test_start_preds += test_preds[0] / len(model_path_list)\n",
    "    test_end_preds += test_preds[1] / len(model_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "test['start'] = test_start_preds.argmax(axis=-1)\n",
    "test['end'] = test_end_preds.argmax(axis=-1)\n",
    "test['selected_text'] = test.apply(lambda x: decode(x['start'], x['end'], x['text'], tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11aa4945ff</td>\n",
       "      <td>wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd1db57dc0</td>\n",
       "      <td>i'm done.haha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2524332d66</td>\n",
       "      <td>i'm concerned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0fb19285b2</td>\n",
       "      <td>hey guys it's working no need to worry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6c9e5e3ab</td>\n",
       "      <td>26th february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>311d2b185b</td>\n",
       "      <td>breaky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95dfefd4e7</td>\n",
       "      <td>2 party 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>739f17cfe1</td>\n",
       "      <td>oh yeah the camera clipping problems with void...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c6322a85c2</td>\n",
       "      <td>_layne hmm.. what's ur fav movie?? tv shows??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b4401d6b4d</td>\n",
       "      <td>salt and vinegar, cheese and onion make your b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                      selected_text\n",
       "0  11aa4945ff                                              wish \n",
       "1  fd1db57dc0                                    i'm done.haha. \n",
       "2  2524332d66                                     i'm concerned \n",
       "3  0fb19285b2           hey guys it's working no need to worry. \n",
       "4  e6c9e5e3ab                                      26th february\n",
       "5  311d2b185b                                            breaky \n",
       "6  95dfefd4e7                                         2 party 4 \n",
       "7  739f17cfe1  oh yeah the camera clipping problems with void...\n",
       "8  c6322a85c2      _layne hmm.. what's ur fav movie?? tv shows??\n",
       "9  b4401d6b4d  salt and vinegar, cheese and onion make your b..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\n",
    "submission['selected_text'] = test[\"selected_text\"]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
